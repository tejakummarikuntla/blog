<!DOCTYPE html>
<html ‚ö°>
<head>
    <meta charset="utf-8">

    <title>Snorkeling in Data for Supervision and Generation</title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="../index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="tejakummarikuntla" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Snorkeling in Data for Supervision and Generation" />
    <meta property="og:description" content="Let&#x27;s Start with &#x27;Why?&#x27;Most of the preprocessing phase of pipelines has the complexity of taking the unstructured data or the Dark Data like text, Tables, Image, etc, and turning into the structured data which usually takes months or years and to build ML models further.Before building an ML" />
    <meta property="og:url" content="tejakummarikuntla.github.io/blog/snorkeling-in-data-for-supervision-and-generation/" />
    <meta property="og:image" content="tejakummarikuntla.github.io/blog/content/images/2020/04/Snorkel_HighLevel_WorkFlow-1.png" />
    <meta property="article:published_time" content="2020-04-26T20:20:58.000Z" />
    <meta property="article:modified_time" content="2020-05-02T16:07:35.000Z" />
    <meta property="article:tag" content="Data Science" />
    
    <meta property="article:publisher" content="https://www.facebook.com/teja.kummarikuntla" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Snorkeling in Data for Supervision and Generation" />
    <meta name="twitter:description" content="Let&#x27;s Start with &#x27;Why?&#x27;Most of the preprocessing phase of pipelines has the complexity of taking the unstructured data or the Dark Data like text, Tables, Image, etc, and turning into the structured data which usually takes months or years and to build ML models further.Before building an ML" />
    <meta name="twitter:url" content="tejakummarikuntla.github.io/blog/snorkeling-in-data-for-supervision-and-generation/" />
    <meta name="twitter:image" content="tejakummarikuntla.github.io/blog/content/images/2020/04/Snorkel_HighLevel_WorkFlow-1.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Teja Kummarikuntla" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Data Science" />
    <meta name="twitter:site" content="@crossmux" />
    <meta name="twitter:creator" content="@crossmux" />
    <meta property="og:image:width" content="1916" />
    <meta property="og:image:height" content="1074" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "tejakummarikuntla",
        "url": "tejakummarikuntla.github.io/blog/",
        "logo": "tejakummarikuntla.github.io/blog/content/images/2020/04/output-onlinepngtools--6-.png"
    },
    "author": {
        "@type": "Person",
        "name": "Teja Kummarikuntla",
        "image": {
            "@type": "ImageObject",
            "url": "tejakummarikuntla.github.io/blog/content/images/2020/04/Screenshot--490-.png",
            "width": 1033,
            "height": 1078
        },
        "url": "tejakummarikuntla.github.io/blog/author/teja/",
        "sameAs": [
            "https://twitter.com/crossmux"
        ]
    },
    "headline": "Snorkeling in Data for Supervision and Generation",
    "url": "tejakummarikuntla.github.io/blog/snorkeling-in-data-for-supervision-and-generation/",
    "datePublished": "2020-04-26T20:20:58.000Z",
    "dateModified": "2020-05-02T16:07:35.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "tejakummarikuntla.github.io/blog/content/images/2020/04/Snorkel_HighLevel_WorkFlow-1.png",
        "width": 1916,
        "height": 1074
    },
    "keywords": "Data Science",
    "description": "Let&#x27;s Start with &#x27;Why?&#x27;\nMost of the preprocessing phase of pipelines has the complexity of taking the\nunstructured data or the Dark Data like text, Tables, Image, etc, and turning\ninto the structured data which usually takes months or years and to build ML\nmodels further.Before building an ML model over the extracted data, we need to\nHand label it, those are called Gold Labels. If we look from Today&#x27;s Machine\nLearning pipeline at a high level this explicitly says that people spent most of\nthe ti",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "tejakummarikuntla.github.io/blog/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.13" />
    <link rel="alternate" type="application/rss+xml" title="tejakummarikuntla" href="../../rss/index.html" />

    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,600,400" />
    <style amp-custom>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:bold}dfn{font-style:italic}h1{margin:0.67em 0;font-size:2em}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{position:relative;vertical-align:baseline;font-size:75%;line-height:0}sup{top:-0.5em}sub{bottom:-0.25em}img{border:0}amp-img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace, monospace;font-size:1em}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{cursor:pointer;-webkit-appearance:button}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{margin:0 2px;padding:0.35em 0.625em 0.75em;border:1px solid #c0c0c0}legend{padding:0;border:0}textarea{overflow:auto}optgroup{font-weight:bold}table{border-spacing:0;border-collapse:collapse}td,th{padding:0}html{max-height:100%;height:100%;font-size:62.5%;-webkit-tap-highlight-color:rgba(0, 0, 0, 0)}body{max-height:100%;height:100%;color:#3a4145;background:#f4f8fb;letter-spacing:0.01rem;font-family:"Merriweather", serif;font-size:1.8rem;line-height:1.75em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"kern" 1;-moz-font-feature-settings:"kern" 1;-o-font-feature-settings:"kern" 1}::-moz-selection{background:#d6edff}::selection{background:#d6edff}h1,h2,h3,h4,h5,h6{margin:0 0 0.3em 0;color:#2e2e2e;font-family:"Open Sans", sans-serif;line-height:1.15em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-moz-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-o-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1}h1{text-indent:-2px;letter-spacing:-1px;font-size:2.6rem}h2{letter-spacing:0;font-size:2.4rem}h3{letter-spacing:-0.6px;font-size:2.1rem}h4{font-size:1.9rem}h5{font-size:1.8rem}h6{font-size:1.8rem}a{color:#4a4a4a}a:hover{color:#111}p,ul,ol,dl{margin:0 0 2.5rem 0;font-size:1.5rem;text-rendering:geometricPrecision;-webkit-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-moz-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-o-font-feature-settings:"liga" 1, "onum" 1, "kern" 1}ol,ul{padding-left:2em}ol ol,ul ul,ul ol,ol ul{margin:0 0 0.4em 0;padding-left:2em}dl dt{float:left;clear:left;overflow:hidden;margin-bottom:1em;width:180px;text-align:right;text-overflow:ellipsis;white-space:nowrap;font-weight:700}dl dd{margin-bottom:1em;margin-left:200px}li{margin:0.4em 0}li li{margin:0}hr{display:block;margin:1.75em 0;padding:0;height:1px;border:0;border-top:#efefef 1px solid}blockquote{box-sizing:border-box;margin:1.75em 0 1.75em 0;padding:0 0 0 1.75em;border-left:#4a4a4a 0.4em solid;-moz-box-sizing:border-box}blockquote p{margin:0.8em 0;font-style:italic}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;color:#ccc;font-size:0.9em}blockquote small:before{content:"\2014 \00A0"}blockquote cite{font-weight:700}blockquote cite a{font-weight:normal}mark{background-color:#fdffb6}code,tt{padding:1px 3px;border:#e3edf3 1px solid;background:#f7fafb;border-radius:2px;white-space:pre-wrap;font-family:Inconsolata, monospace, sans-serif;font-size:0.85em;font-feature-settings:"liga" 0;-webkit-font-feature-settings:"liga" 0;-moz-font-feature-settings:"liga" 0}pre{overflow:auto;box-sizing:border-box;margin:0 0 1.75em 0;padding:10px;width:100%;border:#e3edf3 1px solid;background:#f7fafb;border-radius:3px;white-space:pre;font-family:Inconsolata, monospace, sans-serif;font-size:0.9em;-moz-box-sizing:border-box}pre code,pre tt{padding:0;border:none;background:transparent;white-space:pre-wrap;font-size:inherit}kbd{display:inline-block;margin-bottom:0.4em;padding:1px 8px;border:#ccc 1px solid;background:#f4f4f4;border-radius:4px;box-shadow:0 1px 0 rgba(0, 0, 0, 0.2), 0 1px 0 0 #fff inset;color:#666;text-shadow:#fff 0 1px 0;font-size:0.9em;font-weight:700}table{box-sizing:border-box;margin:1.75em 0;max-width:100%;width:100%;background-color:transparent;-moz-box-sizing:border-box}table th,table td{padding:8px;border-top:#efefef 1px solid;vertical-align:top;text-align:left;line-height:20px}table th{color:#000}table caption + thead tr:first-child th,table caption + thead tr:first-child td,table colgroup + thead tr:first-child th,table colgroup + thead tr:first-child td,table thead:first-child tr:first-child th,table thead:first-child tr:first-child td{border-top:0}table tbody + tbody{border-top:#efefef 2px solid}table table table{background-color:#fff}table tbody > tr:nth-child(odd) > td,table tbody > tr:nth-child(odd) > th{background-color:#f6f6f6}table.plain tbody > tr:nth-child(odd) > td,table.plain tbody > tr:nth-child(odd) > th{background:transparent}iframe,amp-iframe,.fluid-width-video-wrapper{display:block;margin:1.75em 0}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper amp-iframe{margin:0}textarea,select,input{margin:0 0 5px 0;padding:6px 9px;width:260px;outline:0;border:#e7eef2 1px solid;background:#fff;border-radius:4px;box-shadow:none;font-family:"Open Sans", sans-serif;font-size:1.6rem;line-height:1.4em;font-weight:100;-webkit-appearance:none}textarea{min-width:250px;min-height:80px;max-width:340px;width:100%;height:auto}input[type="text"]:focus,input[type="email"]:focus,input[type="search"]:focus,input[type="tel"]:focus,input[type="url"]:focus,input[type="password"]:focus,input[type="number"]:focus,input[type="date"]:focus,input[type="month"]:focus,input[type="week"]:focus,input[type="time"]:focus,input[type="datetime"]:focus,input[type="datetime-local"]:focus,textarea:focus{outline:none;outline-width:0;border:#bbc7cc 1px solid;background:#fff}select{width:270px;height:30px;line-height:30px}.clearfix:before,.clearfix:after{content:" ";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.main-header{position:relative;display:table;overflow:hidden;box-sizing:border-box;width:100%;height:50px;background:#5ba4e5 no-repeat center center;background-size:cover;text-align:left;-webkit-box-sizing:border-box;-moz-box-sizing:border-box}.content{background:#fff;padding-top:15px}.blog-title,.content{margin:auto;max-width:600px}.blog-title a{display:block;padding-right:16px;padding-left:16px;height:50px;color:#fff;text-decoration:none;font-family:"Open Sans", sans-serif;font-size:16px;line-height:50px;font-weight:600}.post{position:relative;margin-top:0;margin-right:16px;margin-left:16px;padding-bottom:0;max-width:100%;border-bottom:#ebf2f6 1px solid;word-wrap:break-word;font-size:0.95em;line-height:1.65em}.post-header{margin-bottom:1rem}.post-title{margin-bottom:0}.post-title a{text-decoration:none}.post-meta{display:block;margin:3px 0 0 0;color:#9eabb3;font-family:"Open Sans", sans-serif;font-size:1.3rem;line-height:2.2rem}.post-meta a{color:#9eabb3;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-meta .author{margin:0;font-size:1.3rem;line-height:1.3em}.post-date{display:inline-block;text-transform:uppercase;white-space:nowrap;font-size:1.2rem;line-height:1.2em}.post-image{margin:0;padding-top:3rem;padding-bottom:30px;border-top:1px #E8E8E8 solid}.post-content amp-img,.post-content amp-anim{position:relative;left:50%;display:block;padding:0;min-width:0;max-width:112%;width:calc(100% + 32px);height:auto;transform:translateX(-50%);-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%)}.footnotes{font-size:1.3rem;line-height:1.6em;font-style:italic}.footnotes li{margin:0.6rem 0}.footnotes p{margin:0}.footnotes p a:last-child{text-decoration:none}.site-footer{position:relative;margin:0 auto 20px auto;padding:1rem 15px;max-width:600px;color:rgba(0,0,0,0.5);font-family:"Open Sans", sans-serif;font-size:1.1rem;line-height:1.75em}.site-footer a{color:rgba(0,0,0,0.5);text-decoration:none;font-weight:bold}.site-footer a:hover{border-bottom:#bbc7cc 1px solid}.poweredby{display:block;float:right;width:45%;text-align:right}.copyright{display:block;float:left;width:45%}</style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="main-header">
        <nav class="blog-title">
            <a href="../../index.html">tejakummarikuntla</a>
        </nav>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Snorkeling in Data for Supervision and Generation</h1>
                <section class="post-meta">
                    <p class="author">by <a href="../../author/teja/index.html">Teja Kummarikuntla</a></p>
                    <time class="post-date" datetime="2020-04-27">2020-04-27</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="tejakummarikuntla.github.io/blog/content/images/2020/04/Snorkel_HighLevel_WorkFlow-1.png" width="600" height="400" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <h2 id="let-s-start-with-why-"><strong>Let's Start with 'Why?'</strong></h2><p>Most of the preprocessing phase of pipelines has the complexity of taking the unstructured data or the Dark Data like text, Tables, Image, etc, and turning into the structured data which usually takes months or years and to build ML models further.Before building an ML model over the extracted data, we need to Hand label it, those are called Gold Labels. If we look from Today's Machine Learning pipeline at a high level this explicitly says that people spent most of the time on creating the Training Dataset and little hustle over Feature Engineering as Deep Learning makes it easy, the crucial part of creating a Training data set is labeling that data points correctly, because the performance of the end model totally depends on how well it trained with correct labels. Now, the question is can we hasten up the process of labeling using any Framework ?, This is where Snorkel began to accelerate Data Building and Managing, not only labeling, snorkel has many other features that make the bottlenecks unclogged.Snorkel: A framework for Rapidly Generating Training Data with Weak Supervision.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption>Snorkel over Data Creation and Feature Engineering.</figcaption></figure><h2 id="weak-supervision"><strong>Weak Supervision</strong></h2><p>By eliminating the Hand labeling process, Now we can programmatically generate labels with external Domain knowledge or any patterns. This results in low-quality lables[Weak labels] more efficiently, which means Weak labels are intended to decrease the cost and increase efficiency. Using noisy, imprecise sources for building a large amount of training data in supervised learning is called Weak Supervision. One of the famous methodologies of weak labeling is Distant supervision. To reiterate Snorkel is an open-source system for quickly assembling training data through weak supervision.</p><h2 id="what-snorkel-can-do"><strong>What Snorkel can do?</strong></h2><p>Snorkel currently has three features for creating and handling training data sets.</p><ul><li><strong><strong>Data Labeling:</strong></strong> Assigning a value to each data point based on Heruristc, Distant Supervision Techniques, etc.,</li><li><strong><strong>Data Transformation:</strong></strong> Converting existing data from one format to another or modifying the data which doesn't affect actual labels. e.g: rotating an image in different angles, etc.,</li><li><strong><strong>Data Slicing:</strong></strong> Segmenting a data set into required subsets for different purposes like improving model perfomance.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption>Source: snorkel.org</figcaption></figure><h2 id="how-snorkel-does-it"><strong>How Snorkel does it?</strong></h2><p>The Hight level Architecture of Snorkel's Workflow consist of Five Steps:</p><ol><li>Writing Labeling Functions. (LFs)</li><li>Modeling and Combining Labeling Functions.</li><li>Writing Transformation Functions for perfoming Data Augmentation.</li><li>Writing Slicing Functions for Subset selection.</li><li>Training a final ML Model.</li></ol><p>Following up these, the takeaway parts of Snorkel is its ability to use labels from different Weak Supervision sources and the set of all labeling functions are modeled by combining and applying a Generative Model [LabelModel] that generates a weak set of labels. Along with that, the system can output Probablistic labels that can be used to train various Classifiers, which indeed generalizes noise labels.</p><figure class="kg-card kg-image-card kg-width-full"></figure><h2 id="data-labeling"><strong>Data Labeling</strong></h2><p>There are few diffent ways that you would totally turn into weak suprevision by using a python decorator <code>labeling_function()</code> or a python class <code>LabelingFunction</code>.</p><ul><li><strong><strong>Heuristics</strong></strong>: applying set of conditions by a pattern, ex: using regular expressions</li><li><strong><strong>Third party Models</strong></strong>: Using an exisiting Model to perfome labeling.</li><li><strong><strong>Distant Supervision</strong></strong>: Using Existing ground truth data that imprecisely fits in, [External Knowledge Bases].</li></ul><p>Let's suppose, we have three different labeling functios are written using conditional pattern and Regular expresions. Expample taken form Snorkel-tutorials.</p><pre><code>@labeling_function()
def check(x):
    return SPAM if "check" in x.text.lower() else ABSTAIN

@labeling_function()
def check_out(x):
    return SPAM if "check out" in x.text.lower() else ABSTAIN
  
# with Regex
@labeling_function()
def regex_check_out(x):
    return SPAM if re.search(r"check.*out", x.text, flags=re.I) else ABSTAIN</code></pre><p>Now, these labeling functions can label in their own way, which is completely independent, the lables would varry.</p><h2 id="applying-lfs"><strong>Applying LFs</strong></h2><p>Snorkel provides Labeling Functions applier for Pandas DataFrames, we can use <code>PandasLFApplier(lfs)</code> which takes a list of labeling functions and return <code>Label Matrix</code> in which each columns represents the outputs of each labeling function in the input list.</p><pre><code>lfs = [check_out, check, regex_check_out]

applier = PandasLFApplier(lfs=lfs)
L_train = applier.apply(df=df_train)</code></pre><figure class="kg-card kg-image-card"></figure><p>For understanding the perfomance and analysing multiple labeling functions let's burst some terminologeis.</p><ul><li><strong><strong>Polarity</strong></strong>: The set of unique labels that LF outputs</li><li><strong><strong>Coverage</strong></strong>: The fraction of the dataset the LF labels</li><li><strong><strong>Overlaps</strong></strong>: The fraction of the dataset where the one LF and atleast one other LF label same.</li><li><strong><strong>Conflicts</strong></strong>: The fraction of the dataset where one LF and at least one other LF label and disagree</li><li><strong><strong>Correct</strong></strong>: The number of data points that the LF labels correctly (if gold labels are provided)</li><li><strong><strong>Incorrect</strong></strong>: The number of data points that this LF labels incorrectly (if gold labels are provided)</li><li><strong><strong>Empirical Accuracy</strong></strong>: The empirical accuracy of the LF (if gold labels are available)</li></ul><p>When we apply LFAnalysis[Labeling Functions Analysis] utility, it results the above metrics for each labeling function.</p><pre><code class="language-python">lfs = [check, check_out, regex_check_out]
LFAnalysis(L=L_train, lfs=lfs).lf_summary(Y=Y_dev)
</code></pre><figure class="kg-card kg-image-card"></figure><p>	After done writing Labeling Functions, and the L_Train has respective columns that represents the corrosponding outputs, our goal is to consie and ¬†generate one standard column which has noise-aware probablistic label per data that can be appended to unlabeled dataset for futher training purpose.</p><p>This process of generating the final label column can be done in few approaches. We can take a Majority vote from the L_train for each data point and result a single value.</p><pre><code class="language-python">from snorkel.labeling import MajorityLabelVoter

majority_model = MajorityLabelVoter()
preds_train = majority_model.predict(L=L_train)
</code></pre><p>One other approch is Snorkel can train a Label Model that takes advange of conflicts between all Labeling Functions and estimate their accuracy. This model with produce a singel set of noise-aware labels, which are porbablistic [Confident-Weighted]. We now can use the resulting probablistic label values to train various classifiers.</p><p>We can use techniques like Logistic Regression, SVM, LSTM at this stage. The discriminative model learn feature representation of our labelling functions and this makes it better able to generalize to unseen data. This will increase the recall and produces final output.</p><pre><code class="language-python">from snorkel.labeling import LabelModel

label_model = LabelModel(cardinality=2, verbose=True)
label_model.fit(L_train=L_train, n_epochs=500, lr=0.001, log_freq=100, seed=123)
preds_train = label_model.predict(L=L_train)
</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption>Source: <a href="https://blog.fastforwardlabs.com/2019/09/27/automating-weak-supervision.html">Automating Weak Supervision</a></figcaption></figure><h2 id="data-transformation">Data Transformation</h2><p>Transformation is a technique of Data Augmentation, a proper data augmentation certainly boosts up the model performance. ¬†Computer vision is the area of work where Data augmentation is used extensively, an Image can be augmented by rotating, flipping or adding filters, etc. When it befalls to the part of Text the complexity of applying Augmentation goes up. A simple example of transforming a text is by replacing the existing words in the document by its synonyms. ¬†But not every word can be replaceable such as a, an, the, etc.</p><p>When we ask what that really makes Data Transformation a big difference is the More the data we have, the better the model performs. ¬†As we transform a data point in different ways, we certainly do not affect the label so it explicitly generates data that could most benefit the training phase.</p><figure class="kg-card kg-image-card kg-card-hascaption"><amp-img src="https://labs.imaginea.com/content/images/2020/01/data_agu_image.png" class="kg-image" width="1418" height="1088" layout="responsive"></amp-img><figcaption>Source: <a href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiD6qW5wZrnAhVC9nMBHSsUDRwQjRx6BAgBEAQ&amp;url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1186%2Fs40537-019-0197-0&amp;psig=AOvVaw1mwDEiBpoljY1029YvQxDz&amp;ust=1579896010264612">Survey on Image Data Augmentation</a></figcaption></figure><h2 id="writing-transformation-functions">Writing Transformation Functions</h2><p>Snorkel provides a python decorator `transformation_function` which takes a single data point and returns the transformed version of it. If the data transformation isn't done it returns `None`, If all the TFs applied to a data point return None, the data point won't be included in the augmented dataset when we apply our TFs below.</p><pre><code class="language-python">@transformation_function(pre=[spacy])
def change_person(x):
    person_names = [ent.text for ent in x.doc.ents if ent.label_ == "PERSON"]
    # If there is at least one person name, replace a random one. Else return None.
    if person_names:
            name_to_replace = np.random.choice(person_names)
            replacement_name = np.random.choice(replacement_names)
            x.text = x.text.replace(name_to_replace, replacement_name)
            return x</code></pre><h3 id="applying-transformation-functions-"><strong>Applying Transformation Functions.</strong></h3><p>A ¬†little similar approach as applying labeling functions, Snorkel provides a specific class for Pandas DataFrame `PandasTFApplier`, where the PandasTFApplier takes list of transformation functions and a Policy, a Policy is used to determine what sequence of Transformation functions to apply, here we use `mean_field_policy`, which allows specifying a sampling distribution for the Transformation Functions.</p><pre><code class="language-python">from snorkel.augmentation import PandasTFApplier

tfs = [change_person, swap_adjectives, replace_verb_with_synonym, replace_noun_with_synonym, replace_adjective_with_synonym]

tf_applier = PandasTFApplier(tfs, mean_field_policy)
df_train_augmented = tf_applier.apply(df_train)
Y_train_augmented = df_train_augmented["label"].values</code></pre><h2 id="reference-"><strong>Reference:</strong></h2><p><a href="https://github.com/snorkel-team/snorkel-tutorials">Snorkel Tutorials</a>; <a href="https://labs.imaginea.com/snorkeling-in-data-for-supervision-and-generation/snorkel.org">snorkel.org</a>; <a href="https://towardsdatascience.com/snorkel-a-weak-supervision-system-a8943c9b639f">Snorkel a weak supervision systerm;</a> <a href="https://www.google.com/search?q=introducing+snorkl+medium&amp;rlz=1C5CHFA_enIN836IN836&amp;oq=introducing+snorkl+medium&amp;aqs=chrome..69i57j33.4575j1j4&amp;sourceid=chrome&amp;ie=UTF-8">Introducing Snorkel</a>; <a href="https://hazyresearch.github.io/snorkel/blog/june-2019-workshop.html">Snorkel-June-2019-workshop</a>;</p><h2 id="my-exprience-at-imaginea-labs-"><strong>My Exprience at Imaginea Labs.</strong></h2><blockquote>A short period of time may not give you much experience, but it leaves you with constructive insights that you could transform the way you admire. ¬† ¬† ¬† - tejakummarikuntla.</blockquote><p>I'm the youngest friend to everyone in the team not only in age but also in thoughts and actions ;p. I always feel that the connections and habits you build will build you back and I tried every day doing it my best. I spent most of my time to Unlearn and relearn in the other dimension that could easily create vivid impressions over the journey and this is the endgame of my Internship journey[24/01/2020].</p><h3 id="tl-dr"><strong>TL;DR</strong></h3><p>Here are a few takeaways that I could only mention by writing. As there are many (intuitions/Familirites) that I couldn't express in words.</p><blockquote>Sri would be probably chuckling when he notices that I tried using Intuition and Familiarity interchangeably [<a href="http://www.userinsight.com/familiarity-breeds-intuition/">Familiarity Breeds Intution</a>]</blockquote><ul><li>Constructive learning approach.</li><li>Learning how to learn.</li><li>Art of not negotiating peculiar advice.</li><li>Aligning the mathematical thinking with programmatical implementation.</li><li>Unlearning.</li><li>Lucid approach to understanding a research paper.</li><li>It's not about how much you know, it's all about what you can devise with it.</li><li>Tracking the new learning by logging in Latex or Markdown.[Zotero]</li><li>You can only know the curx when you keep questioning 'Why?'</li><li>Mathematical bonding not only with life but also with Music and Art [Godel, Escher, Bach]</li><li>You can only Enjoy working when you see a purpose in it.</li><li>Healthy relations will amplify performance.</li><li>When you start expressing, you will start noticing different results.</li><li>Laughing for lame jokes isn't a sin, coz I do a lot ;p [Not lame jokes ] I know it's very lame ;p.</li></ul><p>I've updated my technical progess at <a href="https://www.linkedin.com/tejakummarikuntla/imaginea_assign">GitHub</a> [Never missed a day to commit :D], feel free to check out and keep in touch @ <a href="https://www.linkedin.com/in/tejakummarikuntla">LinkedIn</a>, <a href="https://www.instagram.com/tejakummarikuntla">Instagram</a>.</p><p><strong><strong>Thank you for all my amazing mentors‚ù§Ô∏è:</strong></strong></p><p>Arun Edwin, Vikash, Sachin, Ebby, Vivek, Rehan, Vishwas, Nimmy, Vijay, Swamy, Kripa, Arthy, Sri, Hari.</p><figure class="kg-card kg-image-card kg-width-full kg-card-hascaption"><amp-img src="https://labs.imaginea.com/content/images/2020/01/PSX_20200109_223113--1-.jpg" class="kg-image" width="2000" height="1416" layout="responsive"></amp-img><figcaption>Sachin's Send off [10/01/2020] | Shot on Vikash's OnePlus 7t ü§™</figcaption></figure><p>Originally Published at: <a href="https://labs.imaginea.com/snorkeling-in-data-for-supervision-and-generation/">Imaginea Labs</a></p><figure class="kg-card kg-image-card kg-width-full"><amp-img src="https://labs.imaginea.com/content/images/2020/01/1_iGomvgpRqhDrvJaaxrtT2Q.png" class="kg-image" width="600" height="200" layout="responsive"></amp-img></figure>

            </section>

        </article>
    </main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="../../index.html">tejakummarikuntla</a> &copy; 2020</section>
        <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
    </footer>
</body>
</html>
