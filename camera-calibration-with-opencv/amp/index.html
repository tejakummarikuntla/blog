<!DOCTYPE html>
<html ⚡>
<head>
    <meta charset="utf-8">

    <title>Camera Calibration with OpenCV</title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="../index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="tejakummarikuntla" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Camera Calibration with OpenCV" />
    <meta property="og:description" content="When we talk about camera calibration and Image distortion, we’re talking about what happens when a camera looks at 3D objects in the real world and transforms them into a 2D image. That transformation isn’t perfect. For example, here’s an image of a road and some images" />
    <meta property="og:url" content="tejakummarikuntla.github.io/blog/camera-calibration-with-opencv/" />
    <meta property="og:image" content="tejakummarikuntla.github.io/blog/content/images/2020/05/1_KR71E-iu_Z5PNCUATg6XIA.png" />
    <meta property="article:published_time" content="2019-02-09T15:55:00.000Z" />
    <meta property="article:modified_time" content="2020-05-02T16:11:01.000Z" />
    <meta property="article:tag" content="computer-vision" />
    
    <meta property="article:publisher" content="https://www.facebook.com/teja.kummarikuntla" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Camera Calibration with OpenCV" />
    <meta name="twitter:description" content="When we talk about camera calibration and Image distortion, we’re talking about what happens when a camera looks at 3D objects in the real world and transforms them into a 2D image. That transformation isn’t perfect. For example, here’s an image of a road and some images" />
    <meta name="twitter:url" content="tejakummarikuntla.github.io/blog/camera-calibration-with-opencv/" />
    <meta name="twitter:image" content="tejakummarikuntla.github.io/blog/content/images/2020/05/1_KR71E-iu_Z5PNCUATg6XIA.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Teja Kummarikuntla" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="computer-vision" />
    <meta name="twitter:site" content="@crossmux" />
    <meta name="twitter:creator" content="@crossmux" />
    <meta property="og:image:width" content="658" />
    <meta property="og:image:height" content="269" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "tejakummarikuntla",
        "url": "tejakummarikuntla.github.io/blog/",
        "logo": "tejakummarikuntla.github.io/blog/content/images/2020/04/output-onlinepngtools--6-.png"
    },
    "author": {
        "@type": "Person",
        "name": "Teja Kummarikuntla",
        "image": {
            "@type": "ImageObject",
            "url": "tejakummarikuntla.github.io/blog/content/images/2020/04/Screenshot--490-.png",
            "width": 1033,
            "height": 1078
        },
        "url": "tejakummarikuntla.github.io/blog/author/teja/",
        "sameAs": [
            "https://twitter.com/crossmux"
        ]
    },
    "headline": "Camera Calibration with OpenCV",
    "url": "tejakummarikuntla.github.io/blog/camera-calibration-with-opencv/",
    "datePublished": "2019-02-09T15:55:00.000Z",
    "dateModified": "2020-05-02T16:11:01.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "tejakummarikuntla.github.io/blog/content/images/2020/05/1_KR71E-iu_Z5PNCUATg6XIA.png",
        "width": 658,
        "height": 269
    },
    "keywords": "computer-vision",
    "description": "When we talk about camera calibration and Image distortion, we’re talking about\nwhat happens when a camera looks at 3D objects in the real world and transforms\nthem into a 2D image. That transformation isn’t perfect.\n\nFor example, here’s an image of a road and some images taken through the\ndifferent camera lens that slightly distorted.\n\nAn original picture of the roadDistorted versions of the above picture by\na cameraIn these distorted images, you can see that the edges of the lanes are\nbent and",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "tejakummarikuntla.github.io/blog/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.13" />
    <link rel="alternate" type="application/rss+xml" title="tejakummarikuntla" href="../../rss/index.html" />

    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,600,400" />
    <style amp-custom>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:bold}dfn{font-style:italic}h1{margin:0.67em 0;font-size:2em}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{position:relative;vertical-align:baseline;font-size:75%;line-height:0}sup{top:-0.5em}sub{bottom:-0.25em}img{border:0}amp-img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace, monospace;font-size:1em}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{cursor:pointer;-webkit-appearance:button}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{margin:0 2px;padding:0.35em 0.625em 0.75em;border:1px solid #c0c0c0}legend{padding:0;border:0}textarea{overflow:auto}optgroup{font-weight:bold}table{border-spacing:0;border-collapse:collapse}td,th{padding:0}html{max-height:100%;height:100%;font-size:62.5%;-webkit-tap-highlight-color:rgba(0, 0, 0, 0)}body{max-height:100%;height:100%;color:#3a4145;background:#f4f8fb;letter-spacing:0.01rem;font-family:"Merriweather", serif;font-size:1.8rem;line-height:1.75em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"kern" 1;-moz-font-feature-settings:"kern" 1;-o-font-feature-settings:"kern" 1}::-moz-selection{background:#d6edff}::selection{background:#d6edff}h1,h2,h3,h4,h5,h6{margin:0 0 0.3em 0;color:#2e2e2e;font-family:"Open Sans", sans-serif;line-height:1.15em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-moz-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-o-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1}h1{text-indent:-2px;letter-spacing:-1px;font-size:2.6rem}h2{letter-spacing:0;font-size:2.4rem}h3{letter-spacing:-0.6px;font-size:2.1rem}h4{font-size:1.9rem}h5{font-size:1.8rem}h6{font-size:1.8rem}a{color:#4a4a4a}a:hover{color:#111}p,ul,ol,dl{margin:0 0 2.5rem 0;font-size:1.5rem;text-rendering:geometricPrecision;-webkit-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-moz-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-o-font-feature-settings:"liga" 1, "onum" 1, "kern" 1}ol,ul{padding-left:2em}ol ol,ul ul,ul ol,ol ul{margin:0 0 0.4em 0;padding-left:2em}dl dt{float:left;clear:left;overflow:hidden;margin-bottom:1em;width:180px;text-align:right;text-overflow:ellipsis;white-space:nowrap;font-weight:700}dl dd{margin-bottom:1em;margin-left:200px}li{margin:0.4em 0}li li{margin:0}hr{display:block;margin:1.75em 0;padding:0;height:1px;border:0;border-top:#efefef 1px solid}blockquote{box-sizing:border-box;margin:1.75em 0 1.75em 0;padding:0 0 0 1.75em;border-left:#4a4a4a 0.4em solid;-moz-box-sizing:border-box}blockquote p{margin:0.8em 0;font-style:italic}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;color:#ccc;font-size:0.9em}blockquote small:before{content:"\2014 \00A0"}blockquote cite{font-weight:700}blockquote cite a{font-weight:normal}mark{background-color:#fdffb6}code,tt{padding:1px 3px;border:#e3edf3 1px solid;background:#f7fafb;border-radius:2px;white-space:pre-wrap;font-family:Inconsolata, monospace, sans-serif;font-size:0.85em;font-feature-settings:"liga" 0;-webkit-font-feature-settings:"liga" 0;-moz-font-feature-settings:"liga" 0}pre{overflow:auto;box-sizing:border-box;margin:0 0 1.75em 0;padding:10px;width:100%;border:#e3edf3 1px solid;background:#f7fafb;border-radius:3px;white-space:pre;font-family:Inconsolata, monospace, sans-serif;font-size:0.9em;-moz-box-sizing:border-box}pre code,pre tt{padding:0;border:none;background:transparent;white-space:pre-wrap;font-size:inherit}kbd{display:inline-block;margin-bottom:0.4em;padding:1px 8px;border:#ccc 1px solid;background:#f4f4f4;border-radius:4px;box-shadow:0 1px 0 rgba(0, 0, 0, 0.2), 0 1px 0 0 #fff inset;color:#666;text-shadow:#fff 0 1px 0;font-size:0.9em;font-weight:700}table{box-sizing:border-box;margin:1.75em 0;max-width:100%;width:100%;background-color:transparent;-moz-box-sizing:border-box}table th,table td{padding:8px;border-top:#efefef 1px solid;vertical-align:top;text-align:left;line-height:20px}table th{color:#000}table caption + thead tr:first-child th,table caption + thead tr:first-child td,table colgroup + thead tr:first-child th,table colgroup + thead tr:first-child td,table thead:first-child tr:first-child th,table thead:first-child tr:first-child td{border-top:0}table tbody + tbody{border-top:#efefef 2px solid}table table table{background-color:#fff}table tbody > tr:nth-child(odd) > td,table tbody > tr:nth-child(odd) > th{background-color:#f6f6f6}table.plain tbody > tr:nth-child(odd) > td,table.plain tbody > tr:nth-child(odd) > th{background:transparent}iframe,amp-iframe,.fluid-width-video-wrapper{display:block;margin:1.75em 0}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper amp-iframe{margin:0}textarea,select,input{margin:0 0 5px 0;padding:6px 9px;width:260px;outline:0;border:#e7eef2 1px solid;background:#fff;border-radius:4px;box-shadow:none;font-family:"Open Sans", sans-serif;font-size:1.6rem;line-height:1.4em;font-weight:100;-webkit-appearance:none}textarea{min-width:250px;min-height:80px;max-width:340px;width:100%;height:auto}input[type="text"]:focus,input[type="email"]:focus,input[type="search"]:focus,input[type="tel"]:focus,input[type="url"]:focus,input[type="password"]:focus,input[type="number"]:focus,input[type="date"]:focus,input[type="month"]:focus,input[type="week"]:focus,input[type="time"]:focus,input[type="datetime"]:focus,input[type="datetime-local"]:focus,textarea:focus{outline:none;outline-width:0;border:#bbc7cc 1px solid;background:#fff}select{width:270px;height:30px;line-height:30px}.clearfix:before,.clearfix:after{content:" ";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.main-header{position:relative;display:table;overflow:hidden;box-sizing:border-box;width:100%;height:50px;background:#5ba4e5 no-repeat center center;background-size:cover;text-align:left;-webkit-box-sizing:border-box;-moz-box-sizing:border-box}.content{background:#fff;padding-top:15px}.blog-title,.content{margin:auto;max-width:600px}.blog-title a{display:block;padding-right:16px;padding-left:16px;height:50px;color:#fff;text-decoration:none;font-family:"Open Sans", sans-serif;font-size:16px;line-height:50px;font-weight:600}.post{position:relative;margin-top:0;margin-right:16px;margin-left:16px;padding-bottom:0;max-width:100%;border-bottom:#ebf2f6 1px solid;word-wrap:break-word;font-size:0.95em;line-height:1.65em}.post-header{margin-bottom:1rem}.post-title{margin-bottom:0}.post-title a{text-decoration:none}.post-meta{display:block;margin:3px 0 0 0;color:#9eabb3;font-family:"Open Sans", sans-serif;font-size:1.3rem;line-height:2.2rem}.post-meta a{color:#9eabb3;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-meta .author{margin:0;font-size:1.3rem;line-height:1.3em}.post-date{display:inline-block;text-transform:uppercase;white-space:nowrap;font-size:1.2rem;line-height:1.2em}.post-image{margin:0;padding-top:3rem;padding-bottom:30px;border-top:1px #E8E8E8 solid}.post-content amp-img,.post-content amp-anim{position:relative;left:50%;display:block;padding:0;min-width:0;max-width:112%;width:calc(100% + 32px);height:auto;transform:translateX(-50%);-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%)}.footnotes{font-size:1.3rem;line-height:1.6em;font-style:italic}.footnotes li{margin:0.6rem 0}.footnotes p{margin:0}.footnotes p a:last-child{text-decoration:none}.site-footer{position:relative;margin:0 auto 20px auto;padding:1rem 15px;max-width:600px;color:rgba(0,0,0,0.5);font-family:"Open Sans", sans-serif;font-size:1.1rem;line-height:1.75em}.site-footer a{color:rgba(0,0,0,0.5);text-decoration:none;font-weight:bold}.site-footer a:hover{border-bottom:#bbc7cc 1px solid}.poweredby{display:block;float:right;width:45%;text-align:right}.copyright{display:block;float:left;width:45%}</style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="main-header">
        <nav class="blog-title">
            <a href="../../index.html">tejakummarikuntla</a>
        </nav>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Camera Calibration with OpenCV</h1>
                <section class="post-meta">
                    <p class="author">by <a href="../../author/teja/index.html">Teja Kummarikuntla</a></p>
                    <time class="post-date" datetime="2019-02-09">2019-02-09</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="tejakummarikuntla.github.io/blog/content/images/2020/05/1_KR71E-iu_Z5PNCUATg6XIA.png" width="600" height="400" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <p>When we talk about camera calibration and Image distortion, we’re talking about what happens when a camera looks at 3D objects in the real world and transforms them into a 2D image. That transformation isn’t perfect.</p><p>For example, here’s an image of a road and some images taken through the different camera lens that slightly distorted.</p><figure class="kg-card kg-image-card kg-card-hascaption"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*O41plkKxm9SFvpQEbt_U3A.png" class="kg-image" width="234" height="178" layout="fixed"></amp-img><figcaption>An original picture of the road</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*BLv96PyejmWq1M5xjuKWUA.png" class="kg-image" width="790" height="201" layout="responsive"></amp-img><figcaption>Distorted versions of the above picture by a camera</figcaption></figure><p>In these distorted images, you can see that the edges of the lanes are bent and sort of rounded or stretched outward. Our first step in analyzing camera is to undo this distortion so we can get correct and useful information out of them.</p><h3 id="why-distortion">Why Distortion?</h3><p>Before we get into the code and start correcting for distortion, let’s get some intuition as to how this distortion occurs.</p><p>Here’s a simple model of a camera called the pinhole camera model.</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*7Wh9L_VYNsPbBf5m2u0aXw.png" class="kg-image" width="950" height="514" layout="responsive"></amp-img></figure><p>When a camera looking at an object, it is looking at the world similar to how our eyes do. By focusing the light that’s reflected off of objects in the world. In this case, though a small pinhole, the camera focuses the light that’s reflected off to a 3D traffic sign and forms a 2D image at the back of the camera.</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*R7Ec-32NFWWf9E7K9SgnRA.png" class="kg-image" width="671" height="196" layout="responsive"></amp-img></figure><p>In math, the Transformation from 3D object points, P of X, Y and Z to X and Y is done by a transformative matrix called the<strong> camera matrix(C)</strong>, we’ll be using this to calibrate the camera.</p><p>However, real cameras don’t use tiny pinholes; they use <strong>lenses</strong> to focus on multiple light rays at a time which allows them to quickly form images. But, lenses can introduce <strong>distortion</strong> too.</p><blockquote>Light lays often bend a little too much at the edges of a curved lens of a camera, and this creates the effect that distorts the edges of the images.</blockquote><h3 id="types-of-distortion">Types of Distortion</h3><p><strong><em>Radial Distortion:</em> </strong>Radial Distortion is the most common type that affects the images, In which when a camera captured pictures of straight lines appeared slightly curved or bent</p><figure class="kg-card kg-image-card kg-card-hascaption"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*fUl8POYptRmR4UzCM4Ox8Q.png" class="kg-image" width="771" height="181" layout="responsive"></amp-img><figcaption>Radially Distorted by a camera</figcaption></figure><p><strong><em>Tangential distortion: </em></strong>Tangential distortion occurs mainly because the lens is not parallely aligned to the imaging plane, that makes the image to be extended a little while longer or tilted, it makes the objects appear farther away or even closer than they actually are.</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/750/1*VaeeJWD3M3Qu2BbJ-hyuNg.png" class="kg-image" width="364" height="221" layout="responsive"></amp-img></figure><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*bkF_vos8mQSFe7jy5JXsJA.png" class="kg-image" width="722" height="345" layout="responsive"></amp-img></figure><p>So, In order to reduce the distortion, luckily this distortion can be captured by five numbers called <strong>Distortion Coefficients</strong>, whose values reflect the amount of radial and tangential distortion in an image.</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*kDPV6S_yLNE15lwuC9nxQA.png" class="kg-image" width="642" height="62" layout="responsive"></amp-img></figure><p>If we know the values of all the coefficients, we can use them to calibrate our camera and undistort the distorted images.</p><figure class="kg-card kg-image-card kg-card-hascaption"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*2dc3TTGhlqfQNp_XJY3xKw.png" class="kg-image" width="787" height="210" layout="responsive"></amp-img><figcaption>Undistorting the Distorted Image with Distortion Coefficients.</figcaption></figure><h3 id="measuring-distortion"><strong>Measuring Distortion</strong></h3><p>So, we know that the distortion changes the size and shape of the object in an image. But, how do we calibrate for that?</p><p>Well, we can take pictures of known shapes, then we’ll be able to detect and correct any distortion errors. We could choose any shape to calibrate our camera, and we’ll use a <strong>chessboard.</strong></p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/750/1*kuatnf9nLE0vZsC0qF7pTQ.png" class="kg-image" width="283" height="279" layout="fixed"></amp-img></figure><p>A chessboard is great for calibration because it's regular, high contrast pattern makes it easy to detect automatically. And we know how an undistorted flat chessboard looks like. So, if we use our camera to take pictures of Chessboard at different angles</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*owW3QvK-yQqdVLxkDQn53g.png" class="kg-image" width="774" height="278" layout="responsive"></amp-img></figure><h3 id="finding-corners">Finding Corners</h3><p>Open CV helps to automatically detect the corners and draw on it by <em>findChessboardCorners() </em>and<em> drawChessboardCorners()</em></p><p>Applying both functions to a sample image, results:</p><figure class="kg-card kg-image-card kg-card-hascaption"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*hoHEjJmK58OaO0xmnItayg.png" class="kg-image" width="929" height="531" layout="responsive"></amp-img><figcaption>After applying <em class="markup--em markup--figure-em">findChessboardCorners() </em>and<em class="markup--em markup--figure-em"> drawChessboardCorners()</em></figcaption></figure><pre><code>import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# prepare object points
nx = 8 number of inside corners in x
ny = 6 number of inside corners in y
# Make a list of calibration images
fname = 'calibration_test.png'
img = cv2.imread(fname)
# Convert to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# Find the chessboard corners
ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)
# If found, draw corners
if ret == True:
    # Draw and display the corners
    cv2.drawChessboardCorners(img, (nx, ny), corners, ret)
    plt.imshow(img)</code></pre><h3 id="calibrating-the-camera">Calibrating The Camera</h3><p>In order to Calibrate the camera, the first step will be to read in calibration Images of a chess board. It’s recommended to use at least 20 images to get a reliable calibration, For this, we have a lot of images here, each chess board has eight by six corners to detect,</p><p>To calibrate a camera, OpenCV gives us the <strong><em>calibrateCamera()</em></strong> function</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*-CDYzCBsuSB0uFN9GTd6yw.png" class="kg-image" width="1000" height="121" layout="responsive"></amp-img></figure><p>This takes in Object points, Image points[<em>will understand these points in a moment</em>], and the shape of the image and using these inputs, it calculates and returns</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*VVKMMo_RnI0bUw_6h4CXMA.png" class="kg-image" width="1000" height="187" layout="responsive"></amp-img></figure><p><strong>mtx</strong>: Camera Matrix, which helps to transform 3D objects points to 2D image points.</p><p><strong>dist:</strong> distortion coefficient</p><p>It also returns the position of the camera in the world, with the values of rotation and translation vectors <strong>rvecs, tvecs</strong></p><p>The next function that we require is <strong><em>undistort()</em></strong>.</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*4wjojfc9y4edjrBW_Va0Lw.png" class="kg-image" width="1000" height="167" layout="responsive"></amp-img></figure><p>The undistort function takes in a distorted image, our camera matrix, and distortion coefficients and it returns an <strong>undistorted</strong>, often called <strong>destination image.</strong></p><p>In calibrateCamera() function we need object points and image points.</p><pre><code>import numpy as np 
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
#read in a calibration image
img = mpimg.imread('../calibration_images/calibration1.jpg')
plt.imshow(img)</code></pre><p>First, Done with numpy, openCV, and plotting imports, then we are gonna read the first image <code>calibarion1.jpg</code> and display it.</p><p>Now, we are gonna map the coordinates of the corners in the 2D displayed image which called as <code>imagepoints</code> , to the 3D coordinates of the real, undistorted chessboard corners, which are called as <code>objectpoinst</code>.</p><p>So, we are gonna set up two empty arrays to hold these points, <code>objectpoints</code> and <code>imagepoints</code></p><pre><code># Arrays to store object points and image points from all the images
objpoints = [] # 3D points in real world space
imgpoints = [] # 2D points in image plane</code></pre><p>The object points will all be the same, just the known object corners of the chess board corners for an eight by six board.</p><p>So, we are going to prepare these object points, first by creating six by eight points in an array, each with three columns for the x,y and z coordinates of each corner. We will then initialize all these to 0s using Numpy’s zeros function. The z coordinates will stay zero so leave that as it is but, for our first two columns x and y, use Numpy’s <code>mgrid</code> function to generate the coordinates that we want. <code>mgrid</code> returns the coordinate values for given grid size and shape those coordinates back into two columns, one for x and one for y:</p><pre><code># Prepare obj points, like (0, 0, 0), (1, 0, 0), (2, 0, 0)....., (7, 5, 0)
objp = np.zeros((6*8,3), np.float32)
objp[:,:,] =  mp.mgrid[0:8,0:6].T.reshape(-1,2) # x,y coordinates</code></pre><p>Next to create the <code>imagepoints</code>, we need to consider the distorted calibrated image and detect the corners of the board. OpenCV gives us an easy way to detect chessboard corners with a function called <code>findChessboardCorners()</code>, that returns the corners found in a grayscale image.</p><p>So, we will convert the image to greyscale and then pass that to the <code>findChessboardCorners()</code> function. This function takes in a <code>grayscle</code> image along with the dimensions of the chess board corners. In this case 8 by 6 and last parameter is for any flags; there are none in this example:</p><pre><code># Convert image to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BRG2GRAY)
# Find the Chesse board corners
rer, corners = cv2.findChessboardCorners(gray, (8,6), None)</code></pre><p>If this function detects corners, we are gonna append those points to the image points array and also add our prepared object points <code>objp</code> to the <code>objectpoints</code> array. These object points will be the same for all of the calibration images since they represent a real chessboard.</p><pre><code># If corners are found, add object points, image points
if ret == True:
    imgpoints.append(corners)
    objpoints.append(objp)</code></pre><p>Next, we also draw the detected corners, with a call to <code>drawChessboardCorners()</code> , that takes in our image, corner dimensions and corner points.</p><pre><code># If corners are found, add object points, image points
if ret == True:
    imgpoints.append(corners)
    objpoints.append(objp)
    
    # Draw and display the corners
    img = cv2.drawChessboardCorners(img, (8,6), corners, ret)
    plt.imshow(img)</code></pre><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*7ofE5NjiT0kqLv3YnFMriQ.png" class="kg-image" width="852" height="632" layout="responsive"></amp-img></figure><h3 id="correction-for-distortion">Correction for Distortion</h3><pre><code>import pickle
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# Read in the saved objpoints and imgpoints
dist_pickle = pickle.load( open( "wide_dist_pickle.p", "rb" ) )
objpoints = dist_pickle["objpoints"]
imgpoints = dist_pickle["imgpoints"]
# Read in an image
img = cv2.imread('test_image.png')
def cal_undistort(img, objpoints, imgpoints):
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1:], None, None)
    undist = cv2.undistort(img, mtx, dist, None, mtx)
    return undist
undistorted = cal_undistort(img, objpoints, imgpoints)
f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))
f.tight_layout()
ax1.imshow(img)
ax1.set_title('Original Image', fontsize=50)
ax2.imshow(undistorted)
ax2.set_title('Undistorted Image', fontsize=50)
plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)</code></pre><p>Get <a href="https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/files/Advanced_Lane_Finding_Images/correct_for_distortion/wide_dist_pickle.p" rel="noopener">distortion pickle file</a> and <a href="https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/files/Advanced_Lane_Finding_Images/correct_for_distortion/test_image.png" rel="noopener">test image</a></p><p>Output result:</p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*KR71E-iu_Z5PNCUATg6XIA.png" class="kg-image" width="658" height="269" layout="responsive"></amp-img></figure><p>Reference: Udacity Self Driving Car Engineer Nanodegree</p><p>Originally Published at: <a href="https://medium.com/analytics-vidhya/camera-calibration-with-opencv-f324679c6eb7?source=---------3------------------">Analytics Vidhya</a></p><figure class="kg-card kg-image-card"><amp-img src="https://cdn-images-1.medium.com/max/1000/1*GVQD9AZADus5ilHq8mOxJg.png" class="kg-image" width="600" height="200" layout="responsive"></amp-img></figure>

            </section>

        </article>
    </main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="../../index.html">tejakummarikuntla</a> &copy; 2020</section>
        <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
    </footer>
</body>
</html>
